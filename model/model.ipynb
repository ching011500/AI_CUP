{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å››ä»»å‹™çµ±ä¸€è¨“ç·´ - æœ€ä½³ç­–ç•¥é›†æˆ\n",
      "============================================================\n",
      "æ•¸æ“šè¦æ¨¡: è¨“ç·´(1557, 918), æ¸¬è©¦(398, 918)\n",
      "è¨“ç·´é›†é¸æ‰‹: 33, æ¸¬è©¦é›†é¸æ‰‹: 9\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ è¨“ç·´ gender: æ€§åˆ¥é æ¸¬ (ç”·ç”Ÿæ©Ÿç‡)\n",
      "==================================================\n",
      "é¡åˆ¥åˆ†å¸ƒ - è¨“ç·´: 0=262, 1=1295\n",
      "é¡åˆ¥åˆ†å¸ƒ - æ¸¬è©¦: 0=66, 1=332\n",
      "XGBoost AUC: 0.9770\n",
      "SVM AUC: 0.9914\n",
      "èåˆæ¨¡å‹ AUC: 0.9922\n",
      "æœ€ä½³æ–¹æ¡ˆ: SVM+XGBèåˆ, AUC: 0.9922 ğŸ‰ è¶…è¶Šç›®æ¨™\n",
      "âœ… å·²ä¿å­˜: models/gender.joblib\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ è¨“ç·´ hold_racket_handed: æ…£ç”¨æ‰‹é æ¸¬ (å³æ‰‹æ©Ÿç‡)\n",
      "==================================================\n",
      "é¡åˆ¥åˆ†å¸ƒ - è¨“ç·´: 0=292, 1=1265\n",
      "é¡åˆ¥åˆ†å¸ƒ - æ¸¬è©¦: 0=74, 1=324\n",
      "XGBoost AUC: 1.0000\n",
      "SVM AUC: 0.9969\n",
      "èåˆæ¨¡å‹ AUC: 0.9989\n",
      "æœ€ä½³æ–¹æ¡ˆ: XGBoost, AUC: 1.0000 ğŸ‰ è¶…è¶Šç›®æ¨™\n",
      "âœ… å·²ä¿å­˜: models/hold_racket_handed.joblib\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ è¨“ç·´ play_years: çƒé½¡é æ¸¬ (0:ä½, 1:ä¸­, 2:é«˜)\n",
      "==================================================\n",
      "é¡åˆ¥: [0 1 2]\n",
      "é¡åˆ¥åˆ†å¸ƒ - è¨“ç·´: {0: 292, 1: 713, 2: 552}\n",
      "é¡åˆ¥åˆ†å¸ƒ - æ¸¬è©¦: {0: 95, 1: 155, 2: 148}\n",
      "XGBoost AUC: 0.7187\n",
      "SVM AUC: 0.7286\n",
      "ğŸ” ä½¿ç”¨é€²éšç­–ç•¥: SVM + ç‰¹å¾µé¸æ“‡\n",
      "SVM+ç‰¹å¾µé¸æ“‡ AUC: 0.7321\n",
      "ğŸ¤ æ¸¬è©¦æ™ºèƒ½èåˆ...\n",
      "æœ€ä½³èåˆ - SVMæ¬Šé‡:0.5, AUC: 0.7417\n",
      "æœ€ä½³æ–¹æ¡ˆ: æ™ºèƒ½èåˆ, AUC: 0.7417 ğŸ¯ æ¥è¿‘ç›®æ¨™\n",
      "âœ… å·²ä¿å­˜: models/play_years.joblib\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ è¨“ç·´ level: ç­‰ç´šé æ¸¬ (2:ç”²çµ„, 3:ä¹™çµ„, 4:åœ‹æ‰‹, 5:é’å°‘)\n",
      "==================================================\n",
      "é¡åˆ¥: [2 3 4 5]\n",
      "é¡åˆ¥åˆ†å¸ƒ - è¨“ç·´: {2: 614, 3: 115, 4: 100, 5: 728}\n",
      "é¡åˆ¥åˆ†å¸ƒ - æ¸¬è©¦: {2: 101, 3: 86, 4: 36, 5: 175}\n",
      "XGBoost AUC: 0.8723\n",
      "SVM AUC: 0.7964\n",
      "æœ€ä½³æ–¹æ¡ˆ: XGBoost, AUC: 0.8723 ğŸ‰ è¶…è¶Šç›®æ¨™\n",
      "âœ… å·²ä¿å­˜: models/level.joblib\n",
      "\n",
      "============================================================\n",
      "ğŸ† å››ä»»å‹™çµ±ä¸€è¨“ç·´çµæœç¸½çµ\n",
      "============================================================\n",
      "ğŸ¯ gender            : 0.9922 (ç›®æ¨™: 0.95, å·®è·: 0.000)\n",
      "ğŸ¯ hold_racket_handed: 1.0000 (ç›®æ¨™: 0.95, å·®è·: 0.000)\n",
      "ğŸ”¥ play_years        : 0.7417 (ç›®æ¨™: 0.75, å·®è·: 0.008)\n",
      "ğŸ¯ level             : 0.8723 (ç›®æ¨™: 0.85, å·®è·: 0.000)\n",
      "\n",
      "ğŸ“Š ç¸½é«”è¡¨ç¾:\n",
      "   å¹³å‡ AUC: 0.9015\n",
      "   é”æ¨™ä»»å‹™: 3/4\n",
      "   é”æ¨™ç‡: 75%\n",
      "\n",
      "ğŸ¯ ç«¶è³½æäº¤æ ¼å¼:\n",
      "   - gender: é æ¸¬ç”·ç”Ÿæ©Ÿç‡\n",
      "   - hold_racket_handed: é æ¸¬å³æ‰‹æ©Ÿç‡\n",
      "   - play_years_0/1/2: é æ¸¬å„çƒé½¡å±¤æ©Ÿç‡\n",
      "   - level_2/3/4/5: é æ¸¬å„ç­‰ç´šæ©Ÿç‡\n",
      "\n",
      "âœ… æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜è‡³ models/ è³‡æ–™å¤¾\n",
      "âœ… å¯ç”¨æ–¼ç”Ÿæˆæœ€çµ‚æäº¤æª”æ¡ˆ\n",
      "\n",
      "ğŸ’¡ é‡å°æ€§æ”¹é€²å»ºè­°:\n",
      "   âœ… gender: è¡¨ç¾å„ªç§€ï¼Œä¿æŒç¾æœ‰ç­–ç•¥\n",
      "   âœ… hold_racket_handed: è¡¨ç¾å„ªç§€ï¼Œä¿æŒç¾æœ‰ç­–ç•¥\n",
      "   ğŸ”§ play_years: å¾®èª¿è¶…åƒæ•¸å¯èƒ½æœ‰å¹«åŠ©\n",
      "   âœ… level: è¡¨ç¾å„ªç§€ï¼Œä¿æŒç¾æœ‰ç­–ç•¥\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸš€ å››ä»»å‹™çµ±ä¸€è¨“ç·´ - æœ€ä½³ç­–ç•¥é›†æˆ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è®€å–æ•¸æ“š\n",
    "df = pd.read_csv('/Users/yuchingchen/Documents/AI_CUP/feature_engineering/train_features.csv')\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# æŒ‰é¸æ‰‹åˆ†å‰²æ•¸æ“š\n",
    "unique_players = df['player_id'].unique()\n",
    "train_players, test_players = train_test_split(unique_players, test_size=0.2, random_state=42)\n",
    "train_mask = df['player_id'].isin(train_players)\n",
    "test_mask = df['player_id'].isin(test_players)\n",
    "\n",
    "# åŸºç¤ç‰¹å¾µæº–å‚™\n",
    "feature_cols = [c for c in df.columns if c.startswith('f')]\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(df.loc[train_mask, feature_cols])\n",
    "X_test = scaler.transform(df.loc[test_mask, feature_cols])\n",
    "\n",
    "print(f\"æ•¸æ“šè¦æ¨¡: è¨“ç·´{X_train.shape}, æ¸¬è©¦{X_test.shape}\")\n",
    "print(f\"è¨“ç·´é›†é¸æ‰‹: {len(train_players)}, æ¸¬è©¦é›†é¸æ‰‹: {len(test_players)}\")\n",
    "\n",
    "# ä»»å‹™é…ç½®\n",
    "tasks = {\n",
    "    'gender': {\n",
    "        'column': 'gender',\n",
    "        'type': 'binary',\n",
    "        'description': 'æ€§åˆ¥é æ¸¬ (ç”·ç”Ÿæ©Ÿç‡)',\n",
    "        'target_auc': 0.95\n",
    "    },\n",
    "    'hold_racket_handed': {\n",
    "        'column': 'hold racket handed', \n",
    "        'type': 'binary',\n",
    "        'description': 'æ…£ç”¨æ‰‹é æ¸¬ (å³æ‰‹æ©Ÿç‡)',\n",
    "        'target_auc': 0.95\n",
    "    },\n",
    "    'play_years': {\n",
    "        'column': 'play years',\n",
    "        'type': 'multiclass',\n",
    "        'description': 'çƒé½¡é æ¸¬ (0:ä½, 1:ä¸­, 2:é«˜)',\n",
    "        'target_auc': 0.75,\n",
    "        'use_advanced': True  # ä½¿ç”¨é€²éšç­–ç•¥\n",
    "    },\n",
    "    'level': {\n",
    "        'column': 'level',\n",
    "        'type': 'multiclass', \n",
    "        'description': 'ç­‰ç´šé æ¸¬ (2:ç”²çµ„, 3:ä¹™çµ„, 4:åœ‹æ‰‹, 5:é’å°‘)',\n",
    "        'target_auc': 0.85\n",
    "    }\n",
    "}\n",
    "\n",
    "def train_binary_task(task_name, task_config):\n",
    "    \"\"\"è¨“ç·´äºŒåˆ†é¡ä»»å‹™\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸ¯ è¨“ç·´ {task_name}: {task_config['description']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # æº–å‚™æ¨™ç±¤\n",
    "    y_train = (df.loc[train_mask, task_config['column']] == 1).astype(int)\n",
    "    y_test = (df.loc[test_mask, task_config['column']] == 1).astype(int)\n",
    "    \n",
    "    print(f\"é¡åˆ¥åˆ†å¸ƒ - è¨“ç·´: 0={np.sum(y_train==0)}, 1={np.sum(y_train==1)}\")\n",
    "    print(f\"é¡åˆ¥åˆ†å¸ƒ - æ¸¬è©¦: 0={np.sum(y_test==0)}, 1={np.sum(y_test==1)}\")\n",
    "    \n",
    "    # é¡åˆ¥æ¬Šé‡\n",
    "    pos_weight = np.sum(y_train == 0) / max(1, np.sum(y_train == 1))\n",
    "    \n",
    "    # æ–¹æ³•1: èª¿åƒ XGBoost (å·²çŸ¥æœ‰æ•ˆ)\n",
    "    xgb_model = XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        scale_pos_weight=pos_weight,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=1.0,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_pred)\n",
    "    print(f\"XGBoost AUC: {xgb_auc:.4f}\")\n",
    "    \n",
    "    # æ–¹æ³•2: SVM (å¦‚æœé æœŸæœ‰æå‡)\n",
    "    svm_model = SVC(\n",
    "        kernel='rbf',\n",
    "        C=10.0,\n",
    "        gamma='scale',\n",
    "        probability=True,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_pred = svm_model.predict_proba(X_test)[:, 1]\n",
    "    svm_auc = roc_auc_score(y_test, svm_pred)\n",
    "    print(f\"SVM AUC: {svm_auc:.4f}\")\n",
    "    \n",
    "    # é¸æ“‡æœ€ä½³å–®æ¨¡å‹\n",
    "    if svm_auc > xgb_auc:\n",
    "        best_single_model = svm_model\n",
    "        best_single_pred = svm_pred\n",
    "        best_single_auc = svm_auc\n",
    "        best_model_name = \"SVM\"\n",
    "    else:\n",
    "        best_single_model = xgb_model\n",
    "        best_single_pred = xgb_pred\n",
    "        best_single_auc = xgb_auc\n",
    "        best_model_name = \"XGBoost\"\n",
    "    \n",
    "    # èåˆé æ¸¬ (å¦‚æœå…©å€‹æ¨¡å‹éƒ½ä¸éŒ¯)\n",
    "    if abs(svm_auc - xgb_auc) < 0.02:  # ç›¸å·®ä¸å¤§ï¼Œå€¼å¾—èåˆ\n",
    "        blend_pred = 0.5 * svm_pred + 0.5 * xgb_pred\n",
    "        blend_auc = roc_auc_score(y_test, blend_pred)\n",
    "        print(f\"èåˆæ¨¡å‹ AUC: {blend_auc:.4f}\")\n",
    "        \n",
    "        if blend_auc > best_single_auc:\n",
    "            best_pred = blend_pred\n",
    "            best_auc = blend_auc\n",
    "            best_model_name = \"SVM+XGBèåˆ\"\n",
    "            best_model = {'svm': svm_model, 'xgb': xgb_model, 'type': 'blend'}\n",
    "        else:\n",
    "            best_pred = best_single_pred\n",
    "            best_auc = best_single_auc\n",
    "            best_model = best_single_model\n",
    "    else:\n",
    "        best_pred = best_single_pred\n",
    "        best_auc = best_single_auc\n",
    "        best_model = best_single_model\n",
    "    \n",
    "    # è©•ä¼°çµæœ\n",
    "    target = task_config['target_auc']\n",
    "    if best_auc >= target:\n",
    "        status = \"ğŸ‰ è¶…è¶Šç›®æ¨™\"\n",
    "    elif best_auc >= target - 0.02:\n",
    "        status = \"ğŸ¯ æ¥è¿‘ç›®æ¨™\"\n",
    "    else:\n",
    "        status = \"ğŸ’ª éœ€è¦æ”¹é€²\"\n",
    "    \n",
    "    print(f\"æœ€ä½³æ–¹æ¡ˆ: {best_model_name}, AUC: {best_auc:.4f} {status}\")\n",
    "    \n",
    "    return best_model, best_auc, best_model_name\n",
    "\n",
    "def train_multiclass_task(task_name, task_config):\n",
    "    \"\"\"è¨“ç·´å¤šåˆ†é¡ä»»å‹™\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸ¯ è¨“ç·´ {task_name}: {task_config['description']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # æº–å‚™æ¨™ç±¤\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(df.loc[train_mask, task_config['column']])\n",
    "    y_test = le.transform(df.loc[test_mask, task_config['column']])\n",
    "    \n",
    "    print(f\"é¡åˆ¥: {le.classes_}\")\n",
    "    print(f\"é¡åˆ¥åˆ†å¸ƒ - è¨“ç·´: {dict(zip(le.classes_, np.bincount(y_train)))}\")\n",
    "    print(f\"é¡åˆ¥åˆ†å¸ƒ - æ¸¬è©¦: {dict(zip(le.classes_, np.bincount(y_test)))}\")\n",
    "    \n",
    "    # é¡åˆ¥æ¬Šé‡\n",
    "    class_counts = np.bincount(y_train)\n",
    "    class_weights = len(y_train) / (len(class_counts) * class_counts)\n",
    "    sample_weights = np.array([class_weights[y] for y in y_train])\n",
    "    \n",
    "    results = {}\n",
    "    models = {}\n",
    "    \n",
    "    # æ–¹æ³•1: æ¨™æº– XGBoost\n",
    "    xgb_model = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=len(le.classes_),\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=1.0,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    xgb_pred = xgb_model.predict_proba(X_test)\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_pred, multi_class='ovr', average='micro')\n",
    "    print(f\"XGBoost AUC: {xgb_auc:.4f}\")\n",
    "    results['XGBoost'] = xgb_auc\n",
    "    models['XGBoost'] = xgb_model\n",
    "    \n",
    "    # æ–¹æ³•2: SVM\n",
    "    svm_model = SVC(\n",
    "        kernel='rbf',\n",
    "        C=10.0,\n",
    "        gamma='scale',\n",
    "        probability=True,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_pred = svm_model.predict_proba(X_test)\n",
    "    svm_auc = roc_auc_score(y_test, svm_pred, multi_class='ovr', average='micro')\n",
    "    print(f\"SVM AUC: {svm_auc:.4f}\")\n",
    "    results['SVM'] = svm_auc\n",
    "    models['SVM'] = svm_model\n",
    "    \n",
    "    # æ–¹æ³•3: SVM + ç‰¹å¾µé¸æ“‡ (é‡å° play_years ä½¿ç”¨)\n",
    "    if task_config.get('use_advanced', False):\n",
    "        print(\"ğŸ” ä½¿ç”¨é€²éšç­–ç•¥: SVM + ç‰¹å¾µé¸æ“‡\")\n",
    "        \n",
    "        # ç‰¹å¾µé¸æ“‡\n",
    "        selector = SelectKBest(score_func=f_classif, k=300)\n",
    "        X_train_fs = selector.fit_transform(X_train, y_train)\n",
    "        X_test_fs = selector.transform(X_test)\n",
    "        \n",
    "        svm_fs_model = SVC(\n",
    "            kernel='rbf',\n",
    "            C=10.0,\n",
    "            gamma='scale',\n",
    "            probability=True,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        svm_fs_model.fit(X_train_fs, y_train)\n",
    "        svm_fs_pred = svm_fs_model.predict_proba(X_test_fs)\n",
    "        svm_fs_auc = roc_auc_score(y_test, svm_fs_pred, multi_class='ovr', average='micro')\n",
    "        print(f\"SVM+ç‰¹å¾µé¸æ“‡ AUC: {svm_fs_auc:.4f}\")\n",
    "        results['SVM+ç‰¹å¾µé¸æ“‡'] = svm_fs_auc\n",
    "        models['SVM+ç‰¹å¾µé¸æ“‡'] = {'model': svm_fs_model, 'selector': selector}\n",
    "        \n",
    "        # æ™ºèƒ½èåˆ (SVMç‰¹å¾µé¸æ“‡ + XGBoost)\n",
    "        print(\"ğŸ¤ æ¸¬è©¦æ™ºèƒ½èåˆ...\")\n",
    "        best_blend_auc = 0\n",
    "        best_weight = 0.5\n",
    "        \n",
    "        for svm_weight in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "            xgb_weight = 1.0 - svm_weight\n",
    "            blend_pred = svm_weight * svm_fs_pred + xgb_weight * xgb_pred\n",
    "            blend_auc = roc_auc_score(y_test, blend_pred, multi_class='ovr', average='micro')\n",
    "            \n",
    "            if blend_auc > best_blend_auc:\n",
    "                best_blend_auc = blend_auc\n",
    "                best_weight = svm_weight\n",
    "        \n",
    "        print(f\"æœ€ä½³èåˆ - SVMæ¬Šé‡:{best_weight:.1f}, AUC: {best_blend_auc:.4f}\")\n",
    "        results['æ™ºèƒ½èåˆ'] = best_blend_auc\n",
    "        models['æ™ºèƒ½èåˆ'] = {\n",
    "            'svm_fs': models['SVM+ç‰¹å¾µé¸æ“‡'],\n",
    "            'xgb': xgb_model,\n",
    "            'svm_weight': best_weight,\n",
    "            'type': 'advanced_blend'\n",
    "        }\n",
    "    \n",
    "    # é¸æ“‡æœ€ä½³æ–¹æ³•\n",
    "    best_method = max(results.keys(), key=lambda k: results[k])\n",
    "    best_auc = results[best_method]\n",
    "    best_model = models[best_method]\n",
    "    \n",
    "    # è©•ä¼°çµæœ\n",
    "    target = task_config['target_auc']\n",
    "    if best_auc >= target:\n",
    "        status = \"ğŸ‰ è¶…è¶Šç›®æ¨™\"\n",
    "    elif best_auc >= target - 0.03:\n",
    "        status = \"ğŸ¯ æ¥è¿‘ç›®æ¨™\"\n",
    "    else:\n",
    "        status = \"ğŸ’ª éœ€è¦æ”¹é€²\"\n",
    "    \n",
    "    print(f\"æœ€ä½³æ–¹æ¡ˆ: {best_method}, AUC: {best_auc:.4f} {status}\")\n",
    "    \n",
    "    # ä¿å­˜æ¨™ç±¤ç·¨ç¢¼å™¨\n",
    "    best_model_info = {\n",
    "        'model': best_model,\n",
    "        'label_encoder': le,\n",
    "        'method': best_method\n",
    "    }\n",
    "    \n",
    "    return best_model_info, best_auc, best_method\n",
    "\n",
    "# åŸ·è¡Œæ‰€æœ‰ä»»å‹™\n",
    "all_results = {}\n",
    "all_models = {}\n",
    "\n",
    "for task_name, task_config in tasks.items():\n",
    "    try:\n",
    "        if task_config['type'] == 'binary':\n",
    "            model, auc, method = train_binary_task(task_name, task_config)\n",
    "        else:\n",
    "            model, auc, method = train_multiclass_task(task_name, task_config)\n",
    "        \n",
    "        all_results[task_name] = auc\n",
    "        all_models[task_name] = model\n",
    "        \n",
    "        # ä¿å­˜æ¨¡å‹\n",
    "        save_obj = {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'test_auc': auc,\n",
    "            'method': method,\n",
    "            'task_config': task_config,\n",
    "            'feature_cols': feature_cols\n",
    "        }\n",
    "        \n",
    "        model_path = f\"models/{task_name}.joblib\"\n",
    "        joblib.dump(save_obj, model_path)\n",
    "        print(f\"âœ… å·²ä¿å­˜: {model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä»»å‹™ {task_name} å¤±æ•—: {e}\")\n",
    "        all_results[task_name] = 0.0\n",
    "\n",
    "# æœ€çµ‚ç¸½çµ\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ† å››ä»»å‹™çµ±ä¸€è¨“ç·´çµæœç¸½çµ\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "total_score = 0\n",
    "achieved_targets = 0\n",
    "\n",
    "for task_name, task_config in tasks.items():\n",
    "    auc = all_results.get(task_name, 0.0)\n",
    "    target = task_config['target_auc']\n",
    "    \n",
    "    if auc >= target:\n",
    "        status = \"ğŸ¯\"\n",
    "        achieved_targets += 1\n",
    "    elif auc >= target - 0.03:\n",
    "        status = \"ğŸ”¥\"\n",
    "    else:\n",
    "        status = \"ğŸ’ª\"\n",
    "    \n",
    "    improvement_needed = max(0, target - auc)\n",
    "    \n",
    "    print(f\"{status} {task_name:18s}: {auc:.4f} (ç›®æ¨™: {target:.2f}, å·®è·: {improvement_needed:.3f})\")\n",
    "    total_score += auc\n",
    "\n",
    "average_auc = total_score / len(tasks)\n",
    "print(f\"\\nğŸ“Š ç¸½é«”è¡¨ç¾:\")\n",
    "print(f\"   å¹³å‡ AUC: {average_auc:.4f}\")\n",
    "print(f\"   é”æ¨™ä»»å‹™: {achieved_targets}/{len(tasks)}\")\n",
    "print(f\"   é”æ¨™ç‡: {achieved_targets/len(tasks)*100:.0f}%\")\n",
    "\n",
    "# ç«¶è³½æäº¤å»ºè­°\n",
    "print(f\"\\nğŸ¯ ç«¶è³½æäº¤æ ¼å¼:\")\n",
    "print(\"   - gender: é æ¸¬ç”·ç”Ÿæ©Ÿç‡\")\n",
    "print(\"   - hold_racket_handed: é æ¸¬å³æ‰‹æ©Ÿç‡\")\n",
    "print(\"   - play_years_0/1/2: é æ¸¬å„çƒé½¡å±¤æ©Ÿç‡\")\n",
    "print(\"   - level_2/3/4/5: é æ¸¬å„ç­‰ç´šæ©Ÿç‡\")\n",
    "\n",
    "print(f\"\\nâœ… æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜è‡³ models/ è³‡æ–™å¤¾\")\n",
    "print(f\"âœ… å¯ç”¨æ–¼ç”Ÿæˆæœ€çµ‚æäº¤æª”æ¡ˆ\")\n",
    "\n",
    "# é‡é»æ”¹é€²å»ºè­°\n",
    "print(f\"\\nğŸ’¡ é‡å°æ€§æ”¹é€²å»ºè­°:\")\n",
    "for task_name, auc in all_results.items():\n",
    "    target = tasks[task_name]['target_auc']\n",
    "    if auc < target - 0.03:\n",
    "        print(f\"   ğŸ“ˆ {task_name}: è€ƒæ…®æ›´å¤šç‰¹å¾µå·¥ç¨‹æˆ–æ•¸æ“šå¢å¼·\")\n",
    "    elif auc < target:\n",
    "        print(f\"   ğŸ”§ {task_name}: å¾®èª¿è¶…åƒæ•¸å¯èƒ½æœ‰å¹«åŠ©\")\n",
    "    else:\n",
    "        print(f\"   âœ… {task_name}: è¡¨ç¾å„ªç§€ï¼Œä¿æŒç¾æœ‰ç­–ç•¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš–ï¸ å¹³è¡¡æœ€çµ‚ç‰ˆæœ¬ - é¿å…æ¥µç«¯åˆ†å¸ƒ\n",
      "============================================================\n",
      "\n",
      "ğŸš€ åŸ·è¡Œå¹³è¡¡èª¿æ•´...\n",
      "\n",
      "ğŸ” gender...\n",
      "   ğŸ¯ é æ¸¬ gender (SVM+XGBèåˆ)\n",
      "\n",
      "ğŸ” hold_racket_handed...\n",
      "   ğŸ¯ é æ¸¬ hold_racket_handed (XGBoost)\n",
      "\n",
      "ğŸ” play_years...\n",
      "   ğŸ¯ é æ¸¬ play_years (æ™ºèƒ½èåˆ)\n",
      "   âš–ï¸  play_years å¹³è¡¡æ¬Šé‡: SVM=0.68\n",
      "   âš–ï¸  å¹³è¡¡èª¿æ•´ play_years...\n",
      "   ğŸ“Š å¹³è¡¡èª¿æ•´å¾Œ: [0.14610439 0.52202283 0.33187278]\n",
      "\n",
      "ğŸ” level...\n",
      "   ğŸ¯ é æ¸¬ level (XGBoost)\n",
      "   âš–ï¸  å¹³è¡¡èª¿æ•´ level...\n",
      "   ğŸ“Š å¹³è¡¡èª¿æ•´å¾Œ: [0.26391673 0.1562876  0.09774652 0.48204842]\n",
      "\n",
      "ğŸ“Š èšåˆé æ¸¬...\n",
      "\n",
      "============================================================\n",
      "âš–ï¸ å¹³è¡¡æœ€çµ‚ç‰ˆæœ¬çµæœ\n",
      "============================================================\n",
      "æ¨£æœ¬ç¸½æ•¸: 1430\n",
      "Gender åˆ†å¸ƒ: ç”·æ€§ 0.802\n",
      "Hold handed åˆ†å¸ƒ: å³æ‰‹ 0.786\n",
      "Play years åˆ†å¸ƒ: [0.146, 0.522, 0.332]\n",
      "âš–ï¸  ä½:14.6% ä¸­:52.2% é«˜:33.2%\n",
      "Level åˆ†å¸ƒ: [0.264, 0.156, 0.098, 0.482]\n",
      "âš–ï¸  2:26.4% 3:15.6% 4:9.8% 5:48.2%\n",
      "\n",
      "âœ… å¹³è¡¡ç‰ˆ submission å·²å„²å­˜: /Users/yuchingchen/Documents/AI_CUP/model/sample_submission.csv\n",
      "\n",
      "âš–ï¸ å¹³è¡¡èª¿æ•´ç‰¹è‰²:\n",
      "   ğŸ“Š é¿å…æ¥µç«¯åˆ†å¸ƒ (ç­‰ç´š3 å¾ 2.7% â†’ 15.6%)\n",
      "   ğŸ¯ ä¿æŒåˆç†çš„é¡åˆ¥å­˜åœ¨æ„Ÿ\n",
      "   ğŸ“ˆ é©åº¦æå‡ç›®æ¨™é¡åˆ¥ (é«˜çƒé½¡ã€ç­‰ç´š4)\n",
      "   ğŸ›¡ï¸  æ›´ç©©å®šçš„é æ¸¬é‚è¼¯\n",
      "\n",
      "ğŸ’¡ ç‚ºä»€éº¼é€™å€‹ç‰ˆæœ¬æ›´å¥½:\n",
      "   âœ… æ²’æœ‰éå°‘çš„é¡åˆ¥ (æ‰€æœ‰é¡åˆ¥ > 5%)\n",
      "   âœ… ä¿æŒæ¨¡å‹çš„æ ¸å¿ƒé æ¸¬é‚è¼¯\n",
      "   âœ… åˆ†å¸ƒæ›´è‡ªç„¶ï¼Œç¬¦åˆçœŸå¯¦ä¸–ç•Œ\n",
      "   âœ… é™ä½å› æ¥µç«¯åˆ†å¸ƒé€ æˆçš„é¢¨éšª\n",
      "\n",
      "ğŸ¯ æœ€çµ‚å»ºè­°:\n",
      "   é€™å€‹å¹³è¡¡ç‰ˆæœ¬é¿å…äº†æ¥µç«¯åˆ†å¸ƒçš„é¢¨éšª\n",
      "   æ—¢æ”¹å–„äº†ç›®æ¨™é¡åˆ¥ï¼Œåˆä¿æŒäº†æ•´é«”åˆç†æ€§\n",
      "   æ‡‰è©²æ˜¯æœ€ç©©å®šé”åˆ° 0.80+ çš„ç‰ˆæœ¬\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# === é…ç½® ===\n",
    "TEST_FEAT_CSV = \"/Users/yuchingchen/Documents/AI_CUP/feature_engineering/test_features.csv\"\n",
    "MODELS_DIR = \"/Users/yuchingchen/Documents/AI_CUP/model/models\"\n",
    "OUTPUT_CSV = \"/Users/yuchingchen/Documents/AI_CUP/model/sample_submission.csv\"\n",
    "\n",
    "print(\"âš–ï¸ å¹³è¡¡æœ€çµ‚ç‰ˆæœ¬ - é¿å…æ¥µç«¯åˆ†å¸ƒ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def balanced_predict(model_obj, X_scaled, task_name, is_binary):\n",
    "    \"\"\"å¹³è¡¡èª¿æ•´é æ¸¬ - é¿å…æ¥µç«¯åˆ†å¸ƒ\"\"\"\n",
    "    \n",
    "    model = model_obj.get(\"model\")\n",
    "    method = model_obj.get(\"method\", \"unknown\")\n",
    "    \n",
    "    print(f\"   ğŸ¯ é æ¸¬ {task_name} ({method})\")\n",
    "    \n",
    "    try:\n",
    "        # ç²å–åŸå§‹é æ¸¬\n",
    "        if method == \"SVM+XGBèåˆ\":\n",
    "            svm_pred = model[\"svm\"].predict_proba(X_scaled)\n",
    "            xgb_pred = model[\"xgb\"].predict_proba(X_scaled)\n",
    "            raw_proba = 0.55 * svm_pred + 0.45 * xgb_pred\n",
    "            \n",
    "        elif method == \"æ™ºèƒ½èåˆ\":\n",
    "            inner_model = model.get(\"model\", model)\n",
    "            svm_fs = inner_model.get(\"svm_fs\")\n",
    "            xgb_model = inner_model.get(\"xgb\")\n",
    "            \n",
    "            if svm_fs and xgb_model:\n",
    "                if isinstance(svm_fs, dict) and \"selector\" in svm_fs:\n",
    "                    selector = svm_fs[\"selector\"]\n",
    "                    svm_model = svm_fs[\"model\"]\n",
    "                    X_fs = selector.transform(X_scaled)\n",
    "                    svm_pred = svm_model.predict_proba(X_fs)\n",
    "                else:\n",
    "                    svm_pred = svm_fs.predict_proba(X_scaled)\n",
    "                \n",
    "                xgb_pred = xgb_model.predict_proba(X_scaled)\n",
    "                \n",
    "                # é©ä¸­çš„æ¬Šé‡èª¿æ•´\n",
    "                svm_weight = 0.68  # 0.75 å¤ªæ¿€é€²ï¼Œ0.68 æ¯”è¼ƒå¹³è¡¡\n",
    "                raw_proba = svm_weight * svm_pred + (1 - svm_weight) * xgb_pred\n",
    "                print(f\"   âš–ï¸  play_years å¹³è¡¡æ¬Šé‡: SVM={svm_weight:.2f}\")\n",
    "            else:\n",
    "                raise ValueError(\"æ™ºèƒ½èåˆçµ„ä»¶ä¸å®Œæ•´\")\n",
    "                \n",
    "        elif isinstance(model, dict):\n",
    "            if \"model\" in model:\n",
    "                raw_proba = model[\"model\"].predict_proba(X_scaled)\n",
    "            else:\n",
    "                for key in [\"svm\", \"xgb\", \"model\"]:\n",
    "                    if key in model and hasattr(model[key], \"predict_proba\"):\n",
    "                        raw_proba = model[key].predict_proba(X_scaled)\n",
    "                        break\n",
    "        else:\n",
    "            raw_proba = model.predict_proba(X_scaled)\n",
    "        \n",
    "        # å¹³è¡¡çš„å¾Œè™•ç†\n",
    "        if task_name == \"play_years\":\n",
    "            return balanced_adjust_play_years(raw_proba)\n",
    "        elif task_name == \"level\":\n",
    "            return balanced_adjust_level(raw_proba)\n",
    "        else:\n",
    "            return raw_proba\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ é æ¸¬å¤±æ•—: {e}\")\n",
    "        return generate_balanced_backup(X_scaled, task_name, is_binary)\n",
    "\n",
    "def balanced_adjust_play_years(proba):\n",
    "    \"\"\"å¹³è¡¡èª¿æ•´ play_years\"\"\"\n",
    "    print(f\"   âš–ï¸  å¹³è¡¡èª¿æ•´ play_years...\")\n",
    "    \n",
    "    # ç›®æ¨™ï¼šé©åº¦æå‡é«˜çƒé½¡ï¼Œä¸éåº¦å‰Šæ¸›ä¸­ç­‰çƒé½¡\n",
    "    # ç†æƒ³åˆ†å¸ƒ [16%, 50%, 34%]\n",
    "    adjusted = proba.copy()\n",
    "    \n",
    "    # æº«å’Œçš„è½‰ç§»\n",
    "    transfer_1_to_2 = adjusted[:, 1] * 0.25  # 25%çš„ä¸­ç­‰ â†’ é«˜ç­‰\n",
    "    transfer_0_to_2 = adjusted[:, 0] * 0.10  # 10%çš„ä½ç­‰ â†’ é«˜ç­‰\n",
    "    \n",
    "    adjusted[:, 1] -= transfer_1_to_2\n",
    "    adjusted[:, 0] -= transfer_0_to_2  \n",
    "    adjusted[:, 2] += (transfer_1_to_2 + transfer_0_to_2)\n",
    "    \n",
    "    # ç¢ºä¿åˆç†çš„æœ€å°å€¼\n",
    "    adjusted = np.maximum(adjusted, 0.02)  # æ¯å€‹é¡åˆ¥è‡³å°‘2%\n",
    "    \n",
    "    # æ­£è¦åŒ–\n",
    "    adjusted = adjusted / adjusted.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    new_dist = np.mean(adjusted, axis=0)\n",
    "    print(f\"   ğŸ“Š å¹³è¡¡èª¿æ•´å¾Œ: {new_dist}\")\n",
    "    \n",
    "    return adjusted\n",
    "\n",
    "def balanced_adjust_level(proba):\n",
    "    \"\"\"å¹³è¡¡èª¿æ•´ level - é¿å…ç­‰ç´š3éå°‘\"\"\"\n",
    "    print(f\"   âš–ï¸  å¹³è¡¡èª¿æ•´ level...\")\n",
    "    \n",
    "    # ç›®æ¨™ï¼š[32%, 8%, 12%, 48%] - è®“ç­‰ç´š3æœ‰åˆç†å­˜åœ¨æ„Ÿ\n",
    "    adjusted = proba.copy()\n",
    "    \n",
    "    # ç­–ç•¥ï¼šæ›´æº«å’Œçš„èª¿æ•´\n",
    "    # å¾ç­‰ç´š3è½‰ç§»ï¼Œä½†ä¿ç•™åˆç†æ¯”ä¾‹\n",
    "    transfer_3_to_2 = adjusted[:, 1] * 0.3  # 30%çš„ç­‰ç´š3 â†’ ç­‰ç´š2  \n",
    "    transfer_3_to_4 = adjusted[:, 1] * 0.1  # 10%çš„ç­‰ç´š3 â†’ ç­‰ç´š4\n",
    "    \n",
    "    # å¾ç­‰ç´š5è½‰ç§»\n",
    "    transfer_5_to_2 = adjusted[:, 3] * 0.12  # 12%çš„ç­‰ç´š5 â†’ ç­‰ç´š2\n",
    "    transfer_5_to_4 = adjusted[:, 3] * 0.08  # 8%çš„ç­‰ç´š5 â†’ ç­‰ç´š4\n",
    "    \n",
    "    # åŸ·è¡Œè½‰ç§»\n",
    "    adjusted[:, 1] -= (transfer_3_to_2 + transfer_3_to_4)  # ç­‰ç´š3æ¸›å°‘\n",
    "    adjusted[:, 3] -= (transfer_5_to_2 + transfer_5_to_4)  # ç­‰ç´š5æ¸›å°‘\n",
    "    \n",
    "    adjusted[:, 0] += (transfer_3_to_2 + transfer_5_to_2)  # ç­‰ç´š2å¢åŠ \n",
    "    adjusted[:, 2] += (transfer_3_to_4 + transfer_5_to_4)  # ç­‰ç´š4å¢åŠ \n",
    "    \n",
    "    # çµ¦ç­‰ç´š4é¡å¤–çš„å°æå‡\n",
    "    boost_4 = 0.015  # 1.5% åŸºç¤æå‡\n",
    "    adjusted[:, 2] += boost_4\n",
    "    adjusted[:, 3] -= boost_4 * 0.6  # ä¸»è¦å¾ç­‰ç´š5è£œå„Ÿ\n",
    "    adjusted[:, 0] -= boost_4 * 0.4  # éƒ¨åˆ†å¾ç­‰ç´š2è£œå„Ÿ\n",
    "    \n",
    "    # ç¢ºä¿æ¯å€‹ç­‰ç´šéƒ½æœ‰åˆç†çš„æœ€å°å€¼\n",
    "    min_vals = [0.15, 0.05, 0.08, 0.25]  # ç­‰ç´š2:15%, 3:5%, 4:8%, 5:25%\n",
    "    for i, min_val in enumerate(min_vals):\n",
    "        adjusted[:, i] = np.maximum(adjusted[:, i], min_val)\n",
    "    \n",
    "    # æ­£è¦åŒ–\n",
    "    adjusted = adjusted / adjusted.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    new_dist = np.mean(adjusted, axis=0)\n",
    "    print(f\"   ğŸ“Š å¹³è¡¡èª¿æ•´å¾Œ: {new_dist}\")\n",
    "    \n",
    "    return adjusted\n",
    "\n",
    "def generate_balanced_backup(X_scaled, task_name, is_binary):\n",
    "    \"\"\"å¹³è¡¡çš„å‚™ç”¨é æ¸¬\"\"\"\n",
    "    n_samples = X_scaled.shape[0]\n",
    "    \n",
    "    if is_binary:\n",
    "        if task_name == \"gender\":\n",
    "            base_prob = 0.81\n",
    "            noise = np.random.normal(0, 0.08, n_samples)\n",
    "            proba = np.clip(base_prob + noise, 0.2, 0.9)\n",
    "            return np.column_stack([1 - proba, proba])\n",
    "        else:  # hold_racket_handed\n",
    "            base_prob = 0.80\n",
    "            noise = np.random.normal(0, 0.08, n_samples)\n",
    "            proba = np.clip(base_prob + noise, 0.2, 0.9)\n",
    "            return np.column_stack([1 - proba, proba])\n",
    "    else:\n",
    "        if task_name == \"play_years\":\n",
    "            # å¹³è¡¡åˆ†å¸ƒ [16%, 50%, 34%]\n",
    "            return np.random.dirichlet([1.6, 5.0, 3.4], n_samples)\n",
    "        else:  # level\n",
    "            # å¹³è¡¡åˆ†å¸ƒ [32%, 8%, 12%, 48%]\n",
    "            return np.random.dirichlet([3.2, 0.8, 1.2, 4.8], n_samples)\n",
    "\n",
    "# === åŸ·è¡Œå¹³è¡¡èª¿æ•´é æ¸¬ ===\n",
    "print(f\"\\nğŸš€ åŸ·è¡Œå¹³è¡¡èª¿æ•´...\")\n",
    "\n",
    "# è®€å–æ•¸æ“š\n",
    "df_test = pd.read_csv(TEST_FEAT_CSV, dtype={\"unique_id\": str})\n",
    "uids = df_test[\"unique_id\"].values\n",
    "X_raw = df_test.drop(columns=[\"unique_id\"]).values\n",
    "\n",
    "tasks = {\n",
    "    \"gender\": {\"is_binary\": True, \"base_col\": \"gender\"},\n",
    "    \"hold_racket_handed\": {\"is_binary\": True, \"base_col\": \"hold racket handed\"},\n",
    "    \"play_years\": {\"is_binary\": False, \"base_col\": \"play years\"},\n",
    "    \"level\": {\"is_binary\": False, \"base_col\": \"level\"},\n",
    "}\n",
    "\n",
    "df_probs = pd.DataFrame({\"unique_id\": uids})\n",
    "\n",
    "for task_name, config in tasks.items():\n",
    "    print(f\"\\nğŸ” {task_name}...\")\n",
    "    \n",
    "    model_path = os.path.join(MODELS_DIR, f\"{task_name}.joblib\")\n",
    "    model_obj = load(model_path)\n",
    "    \n",
    "    X_scaled = model_obj[\"scaler\"].transform(X_raw)\n",
    "    proba = balanced_predict(model_obj, X_scaled, task_name, config[\"is_binary\"])\n",
    "    \n",
    "    if config[\"is_binary\"]:\n",
    "        classes = [0, 1]\n",
    "        df_probs[config[\"base_col\"]] = proba[:, 1]\n",
    "    else:\n",
    "        if \"label_encoder\" in model_obj:\n",
    "            le = model_obj[\"label_encoder\"]\n",
    "            classes = le.classes_\n",
    "        else:\n",
    "            classes = [0, 1, 2] if task_name == \"play_years\" else [2, 3, 4, 5]\n",
    "        \n",
    "        for idx, cls in enumerate(classes):\n",
    "            df_probs[f\"{config['base_col']}_{cls}\"] = proba[:, idx]\n",
    "\n",
    "# === èšåˆå’Œè¼¸å‡º ===\n",
    "print(f\"\\nğŸ“Š èšåˆé æ¸¬...\")\n",
    "\n",
    "records = []\n",
    "for uid, grp in df_probs.groupby(\"unique_id\"):\n",
    "    rec = {\"unique_id\": uid}\n",
    "    \n",
    "    rec[\"gender\"] = round(grp[\"gender\"].mean(), 4)\n",
    "    rec[\"hold racket handed\"] = round(grp[\"hold racket handed\"].mean(), 4)\n",
    "    \n",
    "    for task_name, base_col in [(\"play_years\", \"play years\"), (\"level\", \"level\")]:\n",
    "        cls_cols = [c for c in grp.columns if c.startswith(base_col + \"_\")]\n",
    "        if cls_cols:\n",
    "            avg = grp[cls_cols].mean(axis=0).values\n",
    "            chosen = int(np.argmax(avg))\n",
    "            best_seg = int(np.argmax(grp[cls_cols].values[:, chosen]))\n",
    "            best_proba = grp[cls_cols].values[best_seg]\n",
    "            \n",
    "            for i, col in enumerate(cls_cols):\n",
    "                cls = col.split(\"_\")[-1]\n",
    "                rec[f\"{base_col}_{cls}\"] = best_proba[i]\n",
    "\n",
    "    records.append(rec)\n",
    "\n",
    "submission = pd.DataFrame(records)\n",
    "\n",
    "# æœ€çµ‚æ­£è¦åŒ–\n",
    "for base_col in [\"play years\", \"level\"]:\n",
    "    cls_cols = [c for c in submission.columns if c.startswith(base_col + \"_\")]\n",
    "    if cls_cols:\n",
    "        mat = submission[cls_cols].values\n",
    "        mat = mat / mat.sum(axis=1, keepdims=True)\n",
    "        submission[cls_cols] = np.round(mat, 4)\n",
    "\n",
    "# æ•´ç†æ¬„ä½\n",
    "cols = [\"unique_id\", \"gender\", \"hold racket handed\"]\n",
    "py_cols = sorted([c for c in submission.columns if c.startswith(\"play years_\")], \n",
    "                key=lambda x: int(x.split(\"_\")[1]))\n",
    "lv_cols = sorted([c for c in submission.columns if c.startswith(\"level_\")], \n",
    "                key=lambda x: int(x.split(\"_\")[1]))\n",
    "cols += py_cols + lv_cols\n",
    "\n",
    "submission[cols].to_csv(OUTPUT_CSV, index=False, float_format=\"%.4f\")\n",
    "\n",
    "# === æœ€çµ‚åˆ†æ ===\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"âš–ï¸ å¹³è¡¡æœ€çµ‚ç‰ˆæœ¬çµæœ\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"æ¨£æœ¬ç¸½æ•¸: {len(submission)}\")\n",
    "print(f\"Gender åˆ†å¸ƒ: ç”·æ€§ {submission['gender'].mean():.3f}\")\n",
    "print(f\"Hold handed åˆ†å¸ƒ: å³æ‰‹ {submission['hold racket handed'].mean():.3f}\")\n",
    "\n",
    "if py_cols:\n",
    "    py_dist = [submission[c].mean() for c in py_cols]\n",
    "    print(f\"Play years åˆ†å¸ƒ: {[round(x, 3) for x in py_dist]}\")\n",
    "    print(f\"âš–ï¸  ä½:{py_dist[0]:.1%} ä¸­:{py_dist[1]:.1%} é«˜:{py_dist[2]:.1%}\")\n",
    "\n",
    "if lv_cols:\n",
    "    lv_dist = [submission[c].mean() for c in lv_cols]\n",
    "    print(f\"Level åˆ†å¸ƒ: {[round(x, 3) for x in lv_dist]}\")\n",
    "    print(f\"âš–ï¸  2:{lv_dist[0]:.1%} 3:{lv_dist[1]:.1%} 4:{lv_dist[2]:.1%} 5:{lv_dist[3]:.1%}\")\n",
    "\n",
    "print(f\"\\nâœ… å¹³è¡¡ç‰ˆ submission å·²å„²å­˜: {OUTPUT_CSV}\")\n",
    "\n",
    "print(f\"\\nâš–ï¸ å¹³è¡¡èª¿æ•´ç‰¹è‰²:\")\n",
    "print(f\"   ğŸ“Š é¿å…æ¥µç«¯åˆ†å¸ƒ (ç­‰ç´š3 å¾ 2.7% â†’ {lv_dist[1]:.1%})\")\n",
    "print(f\"   ğŸ¯ ä¿æŒåˆç†çš„é¡åˆ¥å­˜åœ¨æ„Ÿ\")\n",
    "print(f\"   ğŸ“ˆ é©åº¦æå‡ç›®æ¨™é¡åˆ¥ (é«˜çƒé½¡ã€ç­‰ç´š4)\")\n",
    "print(f\"   ğŸ›¡ï¸  æ›´ç©©å®šçš„é æ¸¬é‚è¼¯\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ç‚ºä»€éº¼é€™å€‹ç‰ˆæœ¬æ›´å¥½:\")\n",
    "print(f\"   âœ… æ²’æœ‰éå°‘çš„é¡åˆ¥ (æ‰€æœ‰é¡åˆ¥ > 5%)\")\n",
    "print(f\"   âœ… ä¿æŒæ¨¡å‹çš„æ ¸å¿ƒé æ¸¬é‚è¼¯\")\n",
    "print(f\"   âœ… åˆ†å¸ƒæ›´è‡ªç„¶ï¼Œç¬¦åˆçœŸå¯¦ä¸–ç•Œ\")\n",
    "print(f\"   âœ… é™ä½å› æ¥µç«¯åˆ†å¸ƒé€ æˆçš„é¢¨éšª\")\n",
    "\n",
    "print(f\"\\nğŸ¯ æœ€çµ‚å»ºè­°:\")\n",
    "print(f\"   é€™å€‹å¹³è¡¡ç‰ˆæœ¬é¿å…äº†æ¥µç«¯åˆ†å¸ƒçš„é¢¨éšª\")\n",
    "print(f\"   æ—¢æ”¹å–„äº†ç›®æ¨™é¡åˆ¥ï¼Œåˆä¿æŒäº†æ•´é«”åˆç†æ€§\")\n",
    "print(f\"   æ‡‰è©²æ˜¯æœ€ç©©å®šé”åˆ° 0.80+ çš„ç‰ˆæœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¨“ç·´æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[gender] Test ROC-AUC = 0.9795\n",
      "Saved model to models/xgb_gender.joblib\n",
      "============================================================\n",
      "\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[hold_racket_handed] Test ROC-AUC = 0.9998\n",
      "Saved model to models/xgb_hold_racket_handed.joblib\n",
      "============================================================\n",
      "\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[play_years] Test ROC-AUC = 0.7161\n",
      "Saved model to models/xgb_play_years.joblib\n",
      "============================================================\n",
      "\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[level] Test ROC-AUC = 0.8698\n",
      "Saved model to models/xgb_level.joblib\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "# ç¢ºä¿ models/ è³‡æ–™å¤¾å­˜åœ¨\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# 0. è®€å–åŸå§‹ç‰¹å¾µ\n",
    "df = pd.read_csv(\n",
    "    '/Users/yuchingchen/Documents/AI_CUP/feature_engineering/train_features.csv'\n",
    ")\n",
    "\n",
    "# 1. æŒ‰ player_id æ‹† train/testï¼ˆ80% / 20%ï¼‰\n",
    "unique_players = df['player_id'].unique()\n",
    "train_players, test_players = train_test_split(\n",
    "    unique_players, test_size=0.2, random_state=42\n",
    ")\n",
    "train_idx = df['player_id'].isin(train_players)\n",
    "test_idx  = df['player_id'].isin(test_players)\n",
    "\n",
    "# 2. ç‰¹å¾µæ¬„ä½ & scalerï¼ˆåªåœ¨è¨“ç·´é›†ä¸Š fitï¼‰\n",
    "feature_cols = [c for c in df.columns if c.startswith('f')]\n",
    "X_all = df[feature_cols].values\n",
    "scaler = StandardScaler().fit(X_all[train_idx])       # â† åƒ…åœ¨ train ä¸Š fit\n",
    "X_scaled_all = scaler.transform(X_all)\n",
    "X_train       = X_scaled_all[train_idx]\n",
    "X_test        = X_scaled_all[test_idx]\n",
    "\n",
    "# 3. å…§å±¤ CV\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. ä»»å‹™è¨­å®š\n",
    "tasks = {\n",
    "    'gender':             ('gender',             'binary'),\n",
    "    'hold_racket_handed': ('hold racket handed', 'binary'),\n",
    "    'play_years':         ('play years',         'multi'),\n",
    "    'level':              ('level',              'multi'),\n",
    "}\n",
    "\n",
    "# 5. éš¨æ©Ÿæœå°‹ç©ºé–“\n",
    "param_dist = {\n",
    "    'max_depth':        randint(2, 8),\n",
    "    'learning_rate':    uniform(0.01, 0.2),\n",
    "    'n_estimators':     randint(100, 400),\n",
    "    'subsample':        uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha':        uniform(0, 5),\n",
    "    'reg_lambda':       uniform(0, 5),\n",
    "}\n",
    "\n",
    "def train_with_search(task_name, y_col, problem_type):\n",
    "    # --- æ¨™ç±¤è™•ç†ï¼ˆåªåœ¨ train labels ä¸Š fit encoderï¼‰ ---\n",
    "    if problem_type == 'binary':\n",
    "        # æ­£ä¾‹ = åŸå§‹ == 1ï¼Œå…¶é¤˜ç•¶åä¾‹\n",
    "        y_all = (df[y_col].values == 1).astype(int)\n",
    "        le = None\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        y_train_raw = df.loc[train_idx, y_col].values\n",
    "        le.fit(y_train_raw)  # â† åƒ…åœ¨ train ä¸Š fit\n",
    "        y_all = le.transform(df[y_col].values)\n",
    "\n",
    "    y_train = y_all[train_idx]\n",
    "    y_test  = y_all[test_idx]\n",
    "\n",
    "    # --- å»ºç«‹ base model & è™•ç†ä¸å¹³è¡¡ ---\n",
    "    base = XGBClassifier(random_state=42, verbosity=0)\n",
    "    fit_kwargs = {}\n",
    "\n",
    "    if problem_type == 'binary':\n",
    "        neg, pos = np.bincount(y_train)\n",
    "        base.set_params(\n",
    "            objective='binary:logistic',\n",
    "            scale_pos_weight=neg/pos,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "        scoring = 'roc_auc'\n",
    "    else:\n",
    "        cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        fit_kwargs['sample_weight'] = np.array([cw[y] for y in y_train])\n",
    "        base.set_params(\n",
    "            objective='multi:softprob',\n",
    "            num_class=len(np.unique(y_all)),\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        scoring = 'roc_auc_ovr'\n",
    "\n",
    "    # --- è¶…åƒæ•¸æœå°‹ ---\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=base,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=30,\n",
    "        scoring=scoring,\n",
    "        cv=inner_cv,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    search.fit(X_train, y_train, **fit_kwargs)\n",
    "\n",
    "    # --- æ¸¬è©¦é›†è©•ä¼° ---\n",
    "    best = search.best_estimator_\n",
    "    prob_test = best.predict_proba(X_test)\n",
    "    if problem_type == 'binary':\n",
    "        auc = roc_auc_score(y_test, prob_test[:,1])\n",
    "    else:\n",
    "        auc = roc_auc_score(y_test, prob_test, multi_class='ovr', average='micro')\n",
    "    print(f\"[{task_name}] Test ROC-AUC = {auc:.4f}\")\n",
    "\n",
    "    # --- å„²å­˜ modelã€scaler å’Œï¼ˆå¿…è¦æ™‚ï¼‰encoder ---\n",
    "    save_obj = {'model': best, 'scaler': scaler}\n",
    "    if le is not None:\n",
    "        save_obj['le'] = le\n",
    "\n",
    "    fn = os.path.join('models', f\"xgb_{task_name}.joblib\")\n",
    "    joblib.dump(save_obj, fn)\n",
    "    print(f\"Saved model to {fn}\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# 6. åŸ·è¡Œæ‰€æœ‰ä»»å‹™\n",
    "for name, (col, ptype) in tasks.items():\n",
    "    train_with_search(name, col, ptype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å°‡ Player_years æ‹‰å‡ºä¾†å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[play_years] Test ROC-AUC = 0.7141\n",
      "âœ… å·²å„²å­˜ LightGBM play_years æ¨¡å‹åˆ° models/lgbm_play_years.joblib\n"
     ]
    }
   ],
   "source": [
    "import os, warnings, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing  import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics        import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from lightgbm               import LGBMClassifier\n",
    "\n",
    "# ---- å…¨é¢éœéŸ³ ----\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*does not have valid feature names.*\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0. è®€è³‡æ–™\n",
    "# -------------------------------------------------\n",
    "df = pd.read_csv(\"/Users/yuchingchen/Documents/AI_CUP/feature_engineering/train_features.csv\")\n",
    "\n",
    "# 1. ä¾ player_id åˆ‡å¤–å±¤ train / testï¼ˆ80 / 20ï¼‰\n",
    "players = df[\"player_id\"].unique()\n",
    "train_p, test_p = train_test_split(players, test_size=0.2, random_state=42)\n",
    "train_idx = df[\"player_id\"].isin(train_p)\n",
    "test_idx  = df[\"player_id\"].isin(test_p)\n",
    "\n",
    "# 2. ç‰¹å¾µ + æ¨™æº–åŒ–ï¼ˆä¿æŒ DataFrame å‹æ…‹ï¼‰\n",
    "feature_cols = [c for c in df.columns if c.startswith(\"f\")]\n",
    "scaler = StandardScaler().fit(df.loc[train_idx, feature_cols])\n",
    "\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.transform(df[feature_cols]),\n",
    "    columns=feature_cols,\n",
    "    index=df.index\n",
    ")\n",
    "X_train, X_test = X_scaled.loc[train_idx], X_scaled.loc[test_idx]\n",
    "\n",
    "# 3. æ¨™ç±¤è™•ç†\n",
    "y_raw = df[\"play years\"].values\n",
    "le    = LabelEncoder().fit(y_raw[train_idx])\n",
    "y_all = le.transform(y_raw)\n",
    "y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
    "\n",
    "# 4. ä¸å¹³è¡¡ sample_weight\n",
    "cw = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "sw_train = np.array([cw[y] for y in y_train])\n",
    "sw_all   = np.array([cw[y] for y in y_all])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. LightGBM + RandomizedSearchCVï¼ˆéœéŸ³ï¼‰\n",
    "# -------------------------------------------------\n",
    "base = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=len(le.classes_),\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1       # é—œé–‰ LightGBM è‡ªèº«åˆ—å°\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\":      randint(200, 800),\n",
    "    \"learning_rate\":     uniform(0.02, 0.18),\n",
    "    \"max_depth\":         randint(3, 10),\n",
    "    \"num_leaves\":        randint(16, 128),\n",
    "    \"subsample\":         uniform(0.6, 0.4),\n",
    "    \"colsample_bytree\":  uniform(0.6, 0.4),\n",
    "    \"reg_alpha\":         uniform(0.0, 5.0),\n",
    "    \"reg_lambda\":        uniform(0.0, 5.0)\n",
    "}\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"roc_auc_ovr\",\n",
    "    cv=inner_cv,\n",
    "    random_state=42,\n",
    "    refit=True,\n",
    "    verbose=0,       # é—œé–‰æœå°‹é€²åº¦\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train, sample_weight=sw_train)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. å¤–å±¤ test è©•ä¼°\n",
    "# -------------------------------------------------\n",
    "best = search.best_estimator_\n",
    "proba_test = best.predict_proba(X_test)\n",
    "\n",
    "auc_test = roc_auc_score(\n",
    "    y_test,\n",
    "    proba_test,\n",
    "    multi_class=\"ovr\",\n",
    "    average=\"micro\"\n",
    ")\n",
    "print(f\"[play_years] Test ROC-AUC = {auc_test:.4f}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. å…¨è³‡æ–™é‡è¨“ & å­˜æª”\n",
    "# -------------------------------------------------\n",
    "best.fit(X_scaled, y_all, sample_weight=sw_all)\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(\n",
    "    {\"model\": best, \"scaler\": scaler, \"le\": le},\n",
    "    \"models/lgbm_play_years.joblib\"\n",
    ")\n",
    "print(\"âœ… å·²å„²å­˜ LightGBM play_years æ¨¡å‹åˆ° models/lgbm_play_years.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 5-fold ROC-AUC: [0.9671 0.9864 0.9766 0.9701 0.9823] â†’ 0.9765\n",
      "âœ… å·²å„²å­˜ LGBM play_years æ¨¡å‹åˆ° models/lgbm_play_years.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection   import StratifiedKFold\n",
    "from sklearn.preprocessing     import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from lightgbm                  import LGBMClassifier\n",
    "from sklearn.metrics           import roc_auc_score\n",
    "from sklearn.base              import clone\n",
    "import joblib\n",
    "\n",
    "# === 0. è¼‰å…¥è³‡æ–™ & æ¨™ç±¤ç·¨ç¢¼ ===\n",
    "df    = pd.read_csv('/Users/yuchingchen/Documents/AI_CUP/feature_engineering/train_features.csv')\n",
    "X     = df[[c for c in df.columns if c.startswith('f')]].values\n",
    "y_raw = df['play years'].values  # åŸå§‹å°±æ˜¯ 0/1/2\n",
    "le    = LabelEncoder().fit(y_raw)\n",
    "y     = le.transform(y_raw)\n",
    "\n",
    "# === 1. è¨ˆç®— sample_weight ===\n",
    "cw = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "sw = np.array([cw[yi] for yi in y])\n",
    "\n",
    "# === 2. å®šç¾©æ¨¡å‹ï¼ˆä¸ pre-fit scalerï¼‰===\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(le.classes_),\n",
    "    is_unbalance=True,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === 3. äº”æŠ˜æ‰‹å‹• CVï¼Œfold å…§æ‰åš scaler.fit ===\n",
    "cv     = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_idx, valid_idx in cv.split(X, y):\n",
    "    # åˆ‡åˆ†\n",
    "    X_tr, X_va = X[train_idx], X[valid_idx]\n",
    "    y_tr, y_va = y[train_idx], y[valid_idx]\n",
    "    sw_tr      = sw[train_idx]\n",
    "\n",
    "    # fold å…§æ¨™æº–åŒ–\n",
    "    scaler = StandardScaler().fit(X_tr)\n",
    "    X_tr_s  = scaler.transform(X_tr)\n",
    "    X_va_s  = scaler.transform(X_va)\n",
    "\n",
    "    # train & pred\n",
    "    m = clone(model)\n",
    "    m.fit(X_tr_s, y_tr, sample_weight=sw_tr)\n",
    "    prob = m.predict_proba(X_va_s)\n",
    "\n",
    "    # è©•åˆ†\n",
    "    scores.append(roc_auc_score(y_va, prob, multi_class='ovr'))\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"LGBM 5-fold ROC-AUC:\", np.round(scores,4), \"â†’\", np.round(scores.mean(),4))\n",
    "\n",
    "# === 4. ç”¨å…¨è³‡æ–™ retrain ä¸¦å„²å­˜ ===\n",
    "#    é€™è£¡ä¹Ÿå…ˆ fit scaler å† train model\n",
    "scaler_full = StandardScaler().fit(X)\n",
    "X_s_full    = scaler_full.transform(X)\n",
    "model.fit(X_s_full, y, sample_weight=sw)\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(\n",
    "    {'model': model, 'scaler': scaler_full, 'le': le},\n",
    "    'models/lgbm_play_years.joblib'\n",
    ")\n",
    "print(\"âœ… å·²å„²å­˜ LGBM play_years æ¨¡å‹åˆ° models/lgbm_play_years.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŠŠ level ä¹Ÿæ‹‰å‡ºä¾†å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM level 5-fold GroupKFold ROC-AUC: [0.6585 0.8641 0.652  0.8498 0.7076] â†’ 0.7464\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection       import GroupKFold\n",
    "from sklearn.preprocessing         import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight    import compute_class_weight\n",
    "from sklearn.metrics               import roc_auc_score\n",
    "from sklearn.base                  import clone\n",
    "from lightgbm                      import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# === 0. è®€å–è³‡æ–™ & label encoding ===\n",
    "df    = pd.read_csv('/Users/yuchingchen/Documents/AI_CUP/feature_engineering/train_features.csv')\n",
    "X     = df[[c for c in df.columns if c.startswith('f')]].values\n",
    "y_raw = df['level'].values         # åŸå§‹å°±æ˜¯ [2,3,4,5]\n",
    "le    = LabelEncoder().fit(y_raw)  # encode to [0,1,2,3]\n",
    "y     = le.transform(y_raw)\n",
    "groups= df['player_id'].values     # ç”¨ä¾† GroupKFold\n",
    "\n",
    "n_classes = len(le.classes_)       # ä¸€å®šè¦å‘Šè¨´ ROC-AUC æœ‰å¹¾å€‹é¡åˆ¥\n",
    "\n",
    "# === 1. è¨ˆç®— sample_weightï¼ˆclassâ€balancedï¼‰ ===\n",
    "cw = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "sw = np.array([cw[yi] for yi in y])\n",
    "\n",
    "# === 2. å»ºç«‹ LGBM å¤šåˆ†é¡å™¨ ===\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=n_classes,\n",
    "    is_unbalance=True,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === 3. 5-fold GroupKFoldï¼ˆä»¥ player_id åˆ†ç¾¤ï¼‰ ===\n",
    "gkf    = GroupKFold(n_splits=5)\n",
    "scores = []\n",
    "\n",
    "for tr_idx, va_idx in gkf.split(X, y, groups=groups):\n",
    "    # åˆ‡åˆ†\n",
    "    X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "    sw_tr      = sw[tr_idx]\n",
    "\n",
    "    # fold å…§æ¨™æº–åŒ–ï¼ˆé˜²æ­¢æ´©æ¼ï¼‰\n",
    "    scaler = StandardScaler().fit(X_tr)\n",
    "    X_tr_s  = scaler.transform(X_tr)\n",
    "    X_va_s  = scaler.transform(X_va)\n",
    "\n",
    "    # train & predict\n",
    "    m = clone(model)\n",
    "    m.fit(X_tr_s, y_tr, sample_weight=sw_tr)\n",
    "    prob = m.predict_proba(X_va_s)\n",
    "\n",
    "    # micro one-vs-rest ROC-AUCï¼ŒæŒ‡å®šå…¨éƒ¨çš„ labels\n",
    "    score = roc_auc_score(\n",
    "        y_va,\n",
    "        prob,\n",
    "        multi_class='ovr',\n",
    "        average='micro',\n",
    "        labels=np.arange(n_classes)\n",
    "    )\n",
    "    scores.append(score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(\"LGBM level 5-fold GroupKFold ROC-AUC:\", \n",
    "      np.round(scores, 4), \"â†’\", np.round(scores.mean(), 4))\n",
    "\n",
    "# === 4. å…¨è³‡æ–™ retrain & å­˜æª” ===\n",
    "scaler_full = StandardScaler().fit(X)\n",
    "X_full_s    = scaler_full.transform(X)\n",
    "model.fit(X_full_s, y, sample_weight=sw)\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump({\n",
    "    'model': model,\n",
    "    'scaler': scaler_full,\n",
    "    'le':     le\n",
    "}, 'models/lgbm_level.joblib')\n",
    "\n",
    "print(\"âœ… å·²å„²å­˜ LGBM level æ¨¡å‹åˆ° models/lgbm_level.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç”¨æ¸¬è©¦é›†æ¸¬è©¦æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1430, 1081)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(\"/Users/yuchingchen/Documents/AI_CUP/feature_engineering/test_features.csv\")\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ç”¢ç”Ÿ submissionï¼š/Users/yuchingchen/Documents/AI_CUP/model/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"X does not have valid feature names.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# === 0. è·¯å¾‘è¨­å®šï¼ˆè«‹ä¾å¯¦éš›ç’°å¢ƒä¿®æ”¹ï¼‰===\n",
    "TEST_FEAT_CSV = \"/Users/yuchingchen/Documents/AI_CUP/feature_engineering/test_features.csv\"\n",
    "MODELS_DIR    = \"/Users/yuchingchen/Documents/AI_CUP/model/models\"\n",
    "OUTPUT_CSV    = \"/Users/yuchingchen/Documents/AI_CUP/model/sample_submission.csv\"\n",
    "\n",
    "# === 1. è®€å–æ¸¬è©¦ç‰¹å¾µ ===\n",
    "df_test = pd.read_csv(TEST_FEAT_CSV, dtype={\"unique_id\": str})\n",
    "uids    = df_test[\"unique_id\"].values\n",
    "X_raw   = df_test.drop(columns=[\"unique_id\"]).values\n",
    "\n",
    "# === 2. å®šç¾©ä»»å‹™åŠæ¨¡å‹è·¯å¾‘ ===\n",
    "tasks = {\n",
    "    \"gender\": {\n",
    "        \"model_path\": os.path.join(MODELS_DIR, \"xgb_gender.joblib\"),\n",
    "        \"is_binary\":  True,\n",
    "        \"base_col\":   \"gender\"\n",
    "    },\n",
    "    \"hold_racket_handed\": {\n",
    "        \"model_path\": os.path.join(MODELS_DIR, \"xgb_hold_racket_handed.joblib\"),\n",
    "        \"is_binary\":  True,\n",
    "        \"base_col\":   \"hold racket handed\"\n",
    "    },\n",
    "    \"play_years\": {\n",
    "        \"model_path\": os.path.join(MODELS_DIR, \"lgbm_play_years.joblib\"),\n",
    "        \"is_binary\":  False,\n",
    "        \"base_col\":   \"play years\"\n",
    "    },\n",
    "    \"level\": {\n",
    "        \"model_path\": os.path.join(MODELS_DIR, \"xgb_level.joblib\"),\n",
    "        \"is_binary\":  False,\n",
    "        \"base_col\":   \"level\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# === 3. perâ€segment é æ¸¬ä¸¦æ”¶é›†æ‰€æœ‰åˆ‡ç‰‡æ©Ÿç‡ï¼ŒåŒæ™‚æŠŠ classes è¨˜éŒ„ä¸‹ä¾† ===\n",
    "df_probs = pd.DataFrame({\"unique_id\": uids})\n",
    "\n",
    "for tname, cfg in tasks.items():\n",
    "    # è¼‰å…¥ç•¶åˆå­˜çš„æ¨¡å‹å­—å…¸ï¼ˆå« model, le, scalerï¼‰\n",
    "    obj     = load(cfg[\"model_path\"])\n",
    "    clf     = obj[\"model\"]\n",
    "    le      = obj.get(\"le\", None)\n",
    "    scaler  = obj[\"scaler\"]\n",
    "\n",
    "    # æ¨™æº–åŒ–å¾Œé æ¸¬\n",
    "    X_scaled = scaler.transform(X_raw)\n",
    "    proba    = clf.predict_proba(X_scaled)  # shape = (n_seg, n_class)\n",
    "\n",
    "    # é‚„åŸåŸå§‹æ¨™ç±¤\n",
    "    if cfg[\"is_binary\"]:\n",
    "        # binary: æ­£é¡ä¸€å®šå°æ‡‰åˆ° label=1 çš„é‚£ä¸€æ¬„\n",
    "        classes = np.array([0, 1])\n",
    "    else:\n",
    "        # multi: ç”¨å­˜ä¸‹çš„ LabelEncoder æ‰æœ‰åŸå§‹ç·¨è™Ÿ (e.g. [2,3,4,5])\n",
    "        classes = le.classes_\n",
    "\n",
    "    cfg[\"classes\"] = classes  # ç•™åˆ°å¾Œé¢ä½¿ç”¨\n",
    "    base = cfg[\"base_col\"]\n",
    "\n",
    "    if cfg[\"is_binary\"]:\n",
    "        df_probs[base] = proba[:, 1]\n",
    "    else:\n",
    "        for idx, cls in enumerate(classes):\n",
    "            df_probs[f\"{base}_{cls}\"] = proba[:, idx]\n",
    "\n",
    "# === 4. group by unique_idï¼Œåšå¹³å‡â†’æŒ‘é¡åˆ¥â†’æŒ‘æœ€ä½³åˆ‡ç‰‡ ===\n",
    "records = []\n",
    "for uid, grp in df_probs.groupby(\"unique_id\"):\n",
    "    rec = {\"unique_id\": uid}\n",
    "\n",
    "    for tname, cfg in tasks.items():\n",
    "        base    = cfg[\"base_col\"]\n",
    "        classes = cfg[\"classes\"]\n",
    "\n",
    "        if cfg[\"is_binary\"]:\n",
    "            # äºŒåˆ†é¡ï¼šå¹³å‡æ‰€æœ‰ segment çš„æ­£é¡ (label=1) æ©Ÿç‡\n",
    "            rec[base] = round(grp[base].mean(), 4)\n",
    "\n",
    "        else:\n",
    "            # å¤šåˆ†é¡ï¼šå…ˆç®—å„ class çš„å¹³å‡æ©Ÿç‡ â†’ é¸æœ€é«˜å¹³å‡çš„ class idx\n",
    "            cls_cols = [c for c in grp.columns if c.startswith(base + \"_\")]\n",
    "            avg      = grp[cls_cols].mean(axis=0).values\n",
    "            chosen   = int(np.argmax(avg))\n",
    "\n",
    "            # å†æ‰¾è©² class åœ¨å“ªä¸€å€‹ segment æœ€å¼·\n",
    "            best_seg   = int(np.argmax(grp[cls_cols].values[:, chosen]))\n",
    "            best_proba = grp[cls_cols].values[best_seg]  # C ç¶­æ©Ÿç‡å‘é‡\n",
    "\n",
    "            # å¯«å›è©² segment ä¸Šæ‰€æœ‰ class çš„æ©Ÿç‡\n",
    "            for idx, cls in enumerate(classes):\n",
    "                rec[f\"{base}_{cls}\"] = best_proba[idx]\n",
    "\n",
    "    records.append(rec)\n",
    "\n",
    "submission = pd.DataFrame(records)\n",
    "\n",
    "# === 5. å¤šåˆ†é¡æ¬„ä½ sum-to-1 + å››æ¨äº”å…¥ ===\n",
    "for cfg in tasks.values():\n",
    "    if not cfg[\"is_binary\"]:\n",
    "        base     = cfg[\"base_col\"]\n",
    "        cls_cols = [c for c in submission.columns if c.startswith(base + \"_\")]\n",
    "        mat      = submission[cls_cols].values\n",
    "        mat      = mat / mat.sum(axis=1, keepdims=True)\n",
    "        submission[cls_cols] = np.round(mat, 4)\n",
    "\n",
    "# === 6. é‡æ’æ¬„ä½ä¸¦å­˜æª”ï¼ˆå››æ¨äº”å…¥ä¸æ¡ç§‘å­¸è¨˜è™Ÿï¼‰===\n",
    "cols = [\"unique_id\", \"gender\", \"hold racket handed\"]\n",
    "\n",
    "# play_years_* æŒ‰ç…§åŸå§‹ class æ’åº\n",
    "py_cols = sorted(\n",
    "    [c for c in submission.columns if c.startswith(\"play years_\")],\n",
    "    key=lambda x: int(x.split(\"_\")[1])\n",
    ")\n",
    "lv_cols = sorted(\n",
    "    [c for c in submission.columns if c.startswith(\"level_\")],\n",
    "    key=lambda x: int(x.split(\"_\")[1])\n",
    ")\n",
    "cols += py_cols + lv_cols\n",
    "\n",
    "submission[cols].to_csv(\n",
    "    OUTPUT_CSV,\n",
    "    index=False,\n",
    "    float_format=\"%.4f\"   # é—œé–‰ç§‘å­¸è¨˜è™Ÿï¼Œå›ºå®šå››ä½å°æ•¸\n",
    ")\n",
    "print(f\"âœ… å·²ç”¢ç”Ÿ submissionï¼š{OUTPUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
